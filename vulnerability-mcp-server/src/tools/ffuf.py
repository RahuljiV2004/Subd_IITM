"""
FFUF Web Fuzzer Tool
Wrapper for the FFUF (Fuzz Faster U Fool) web application fuzzer
"""

import os
import json
from typing import Dict, Any
from .base_tool import BaseTool


class FFUFTool(BaseTool):
    """FFUF web application fuzzer implementation"""

    def __init__(self):
        super().__init__()
        self.name = "ffuf"
        self.description = "Fast web application fuzzer"

        # Find ffuf executable
        self.tool_path = self._find_ffuf_path()

    def _find_ffuf_path(self) -> str:
        """Find ffuf executable path"""
        username = os.getenv("USERNAME", os.getenv("USER", "user"))

        possible_paths = [
            # Project tools
            rf"C:\Users\{username}\Documents\My Files\Programes\IITM\Subd_IITM\tools\ffuf.exe",
            # Go installation paths
            rf"C:\Users\{username}\go\bin\ffuf.exe",
            rf"C:\Users\{username}\AppData\Local\go\bin\ffuf.exe",
            # System installations
            "ffuf",  # Should be in PATH
            "/usr/bin/ffuf",
            "/usr/local/bin/ffuf",
        ]

        return self._find_tool_path(possible_paths)

    def get_description(self) -> str:
        return f"FFUF Web Application Fuzzer - Fast directory/file discovery and parameter fuzzing. Path: {self.tool_path}"

    def get_input_schema(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "target": {
                    "type": "string",
                    "description": "Target URL with FUZZ keyword (e.g., https://example.com/FUZZ)",
                },
                "wordlist": {
                    "type": "string",
                    "description": "Path to wordlist file or built-in wordlist name",
                    "default": "common_directories",
                },
                "extensions": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "File extensions to append (e.g., ['php', 'html', 'txt'])",
                },
                "method": {
                    "type": "string",
                    "enum": ["GET", "POST", "PUT", "DELETE", "HEAD", "OPTIONS"],
                    "description": "HTTP method to use",
                    "default": "GET",
                },
                "threads": {
                    "type": "integer",
                    "description": "Number of concurrent threads",
                    "default": 40,
                    "minimum": 1,
                    "maximum": 100,
                },
                "timeout": {
                    "type": "integer",
                    "description": "Request timeout in seconds",
                    "default": 10,
                    "minimum": 1,
                    "maximum": 60,
                },
                "delay": {
                    "type": "integer",
                    "description": "Delay between requests in milliseconds",
                    "default": 0,
                    "minimum": 0,
                },
                "match_status": {
                    "type": "array",
                    "items": {"type": "integer"},
                    "description": "HTTP status codes to match (e.g., [200, 301, 302])",
                    "default": [200, 204, 301, 302, 307, 401, 403, 405],
                },
                "filter_status": {
                    "type": "array",
                    "items": {"type": "integer"},
                    "description": "HTTP status codes to filter out",
                },
                "filter_size": {
                    "type": "array",
                    "items": {"type": "integer"},
                    "description": "Response sizes to filter out",
                },
                "filter_words": {
                    "type": "array",
                    "items": {"type": "integer"},
                    "description": "Word counts to filter out",
                },
                "headers": {
                    "type": "object",
                    "description": "Custom HTTP headers as key-value pairs",
                },
                "cookies": {
                    "type": "string",
                    "description": "Cookie data to include in requests",
                },
                "proxy": {
                    "type": "string",
                    "description": "Proxy URL (e.g., http://proxy:8080)",
                },
                "follow_redirects": {
                    "type": "boolean",
                    "description": "Follow HTTP redirects",
                    "default": False,
                },
                "arguments": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Additional ffuf command-line arguments",
                },
            },
            "required": ["target"],
        }

    async def execute(self, params: Dict[str, Any]) -> str:
        """Execute FFUF web application fuzzing"""
        try:
            # Validate and extract parameters
            target = params["target"]
            if "FUZZ" not in target:
                # Add FUZZ keyword if not present
                if target.endswith("/"):
                    target += "FUZZ"
                else:
                    target += "/FUZZ"

            # Validate target URL
            self._validate_target(target.replace("FUZZ", "example"))

            wordlist = params.get("wordlist", "common_directories")
            extensions = params.get("extensions", [])
            method = params.get("method", "GET")
            threads = params.get("threads", 40)
            timeout = params.get("timeout", 10)
            delay = params.get("delay", 0)
            match_status = params.get(
                "match_status", [200, 204, 301, 302, 307, 401, 403, 405]
            )
            filter_status = params.get("filter_status", [])
            filter_size = params.get("filter_size", [])
            filter_words = params.get("filter_words", [])
            headers = params.get("headers", {})
            cookies = params.get("cookies", "")
            proxy = params.get("proxy", "")
            follow_redirects = params.get("follow_redirects", False)
            extra_args = params.get("arguments", [])

            # Get or create wordlist
            wordlist_path = self._get_wordlist_path(wordlist)

            # Build the command
            cmd = self._build_command(
                target,
                wordlist_path,
                extensions,
                method,
                threads,
                timeout,
                delay,
                match_status,
                filter_status,
                filter_size,
                filter_words,
                headers,
                cookies,
                proxy,
                follow_redirects,
                extra_args,
            )

            # Calculate timeout based on wordlist size and threads
            scan_timeout = self._calculate_timeout(wordlist_path, threads, delay)

            # Execute the fuzzing
            result = await self._execute_command(cmd, timeout=scan_timeout)

            # Format and return results
            return self._format_results(target, result, params)

        except ValueError as e:
            return self._format_error_response(
                str(e),
                suggestions=[
                    "Check target URL format",
                    "Ensure FUZZ keyword is present",
                    "Verify target accessibility",
                ],
            )
        except Exception as e:
            return self._format_error_response(
                f"FFUF execution failed: {str(e)}",
                suggestions=[
                    "Verify FFUF is installed and accessible",
                    "Check target connectivity",
                    "Verify wordlist exists",
                    "Review fuzzing parameters",
                ],
            )

    def _get_wordlist_path(self, wordlist: str) -> str:
        """Get path to wordlist file"""

        # If it's already a file path, return as-is
        if os.path.isfile(wordlist):
            return wordlist

        # Built-in wordlists (create minimal ones if needed)
        username = os.getenv("USERNAME", os.getenv("USER", "user"))
        wordlist_dir = rf"C:\Users\{username}\Documents\My Files\Programes\IITM\Subd_IITM\vulnerability-mcp-server\wordlists"

        # Create wordlist directory if it doesn't exist
        os.makedirs(wordlist_dir, exist_ok=True)

        builtin_wordlists = {
            "common_directories": [
                "admin",
                "administrator",
                "api",
                "app",
                "assets",
                "backup",
                "bin",
                "blog",
                "cache",
                "cgi-bin",
                "config",
                "css",
                "data",
                "db",
                "debug",
                "dev",
                "docs",
                "download",
                "etc",
                "files",
                "images",
                "img",
                "include",
                "includes",
                "js",
                "lib",
                "log",
                "logs",
                "mail",
                "old",
                "panel",
                "private",
                "public",
                "src",
                "static",
                "temp",
                "test",
                "tmp",
                "upload",
                "uploads",
                "user",
                "users",
                "var",
                "web",
                "wp-admin",
                "wp-content",
                "wp-includes",
            ],
            "common_files": [
                "index",
                "home",
                "login",
                "admin",
                "config",
                "robots",
                "sitemap",
                "readme",
                "changelog",
                "license",
                "install",
                "setup",
                "test",
                "backup",
                "database",
                "db",
                "sql",
                "passwd",
                "password",
                "htaccess",
                "web.config",
                "app.config",
                "settings",
            ],
            "common_parameters": [
                "id",
                "user",
                "username",
                "email",
                "password",
                "pass",
                "token",
                "key",
                "api_key",
                "search",
                "query",
                "q",
                "page",
                "limit",
                "offset",
                "sort",
                "order",
                "filter",
                "category",
                "type",
                "action",
                "cmd",
                "command",
                "file",
                "path",
                "url",
                "redirect",
                "callback",
                "debug",
                "test",
            ],
        }

        if wordlist in builtin_wordlists:
            wordlist_file = os.path.join(wordlist_dir, f"{wordlist}.txt")

            # Create wordlist file if it doesn't exist
            if not os.path.exists(wordlist_file):
                with open(wordlist_file, "w", encoding="utf-8") as f:
                    for word in builtin_wordlists[wordlist]:
                        f.write(f"{word}\n")

            return wordlist_file

        # Try common wordlist locations
        common_paths = [
            f"/usr/share/wordlists/{wordlist}",
            f"/usr/share/seclists/{wordlist}",
            f"/opt/wordlists/{wordlist}",
            rf"C:\Tools\wordlists\{wordlist}",
        ]

        for path in common_paths:
            if os.path.isfile(path):
                return path

        # Default to common_directories if wordlist not found
        return self._get_wordlist_path("common_directories")

    def _build_command(
        self,
        target: str,
        wordlist_path: str,
        extensions: list,
        method: str,
        threads: int,
        timeout: int,
        delay: int,
        match_status: list,
        filter_status: list,
        filter_size: list,
        filter_words: list,
        headers: dict,
        cookies: str,
        proxy: str,
        follow_redirects: bool,
        extra_args: list,
    ) -> list:
        """Build the ffuf command"""

        cmd = [self.tool_path]

        # Add target URL
        cmd.extend(["-u", target])

        # Add wordlist
        cmd.extend(["-w", wordlist_path])

        # Add extensions if specified
        if extensions:
            # FFUF can handle extensions with -e flag or by modifying the URL
            ext_list = ",".join(extensions)
            cmd.extend(["-e", ext_list])

        # Add HTTP method
        cmd.extend(["-X", method])

        # Add performance settings
        cmd.extend(["-t", str(threads)])
        cmd.extend(["-timeout", str(timeout)])

        if delay > 0:
            cmd.extend(["-p", f"{delay}ms"])

        # Add matching criteria
        if match_status:
            status_codes = ",".join(map(str, match_status))
            cmd.extend(["-mc", status_codes])

        # Add filters
        if filter_status:
            status_codes = ",".join(map(str, filter_status))
            cmd.extend(["-fc", status_codes])

        if filter_size:
            sizes = ",".join(map(str, filter_size))
            cmd.extend(["-fs", sizes])

        if filter_words:
            words = ",".join(map(str, filter_words))
            cmd.extend(["-fw", words])

        # Add headers
        for key, value in headers.items():
            cmd.extend(["-H", f"{key}: {value}"])

        # Add cookies
        if cookies:
            cmd.extend(["-b", cookies])

        # Add proxy
        if proxy:
            cmd.extend(["-x", proxy])

        # Add redirect behavior
        if follow_redirects:
            cmd.append("-r")

        # Output format (JSON for easier parsing)
        cmd.extend(["-o", "-", "-of", "json"])

        # Suppress banner for cleaner output
        cmd.append("-s")

        # Add any additional arguments
        cmd.extend(extra_args)

        return cmd

    def _calculate_timeout(self, wordlist_path: str, threads: int, delay: int) -> int:
        """Calculate appropriate timeout based on wordlist size and settings"""
        try:
            # Count lines in wordlist
            with open(wordlist_path, "r", encoding="utf-8", errors="ignore") as f:
                wordlist_size = sum(1 for _ in f)
        except:
            wordlist_size = 1000  # Default assumption

        # Estimate time: (wordlist_size / threads) * (average_request_time + delay)
        avg_request_time = 2  # seconds
        estimated_time = (wordlist_size / threads) * (avg_request_time + (delay / 1000))

        # Add buffer and set reasonable bounds
        timeout = max(int(estimated_time * 1.5), 60)  # At least 1 minute
        timeout = min(timeout, 3600)  # Cap at 1 hour

        return timeout

    def _format_results(
        self, target: str, result: Dict[str, Any], params: Dict[str, Any]
    ) -> str:
        """Format FFUF fuzzing results"""

        response = "# ðŸ” FFUF Web Fuzzing Results\n\n"
        response += f"**Target:** {target}\n"
        response += f"**Wordlist:** {params.get('wordlist', 'common_directories')}\n"
        response += f"**Method:** {params.get('method', 'GET')}\n"
        response += f"**Threads:** {params.get('threads', 40)}\n"
        response += f"**Command:** `{result.get('command', 'Unknown')}`\n\n"

        # Check execution status
        if result.get("timed_out"):
            return self._format_timeout_response(
                self._calculate_timeout(
                    self._get_wordlist_path(
                        params.get("wordlist", "common_directories")
                    ),
                    params.get("threads", 40),
                    params.get("delay", 0),
                ),
                target,
            )

        return_code = result.get("return_code", -1)
        stdout = result.get("stdout", "")
        stderr = result.get("stderr", "")

        # Parse results
        findings = self._parse_ffuf_output(stdout)

        # Format summary
        response += "## ðŸ“Š Fuzzing Summary\n\n"
        if return_code == 0:
            response += "**Status:** âœ… Completed Successfully\n"
        else:
            response += f"**Status:** âš ï¸ Completed with issues (code: {return_code})\n"

        response += f"**Results Found:** {len(findings)}\n"

        # Count by status code
        status_counts = {}
        for finding in findings:
            status = finding.get("status", 0)
            status_counts[status] = status_counts.get(status, 0) + 1

        if status_counts:
            response += "**Status Code Distribution:** "
            response += " | ".join(
                [f"{code}: {count}" for code, count in sorted(status_counts.items())]
            )
            response += "\n\n"

        # Format findings
        if findings:
            response += "## ðŸ“ Discovered Paths\n\n"

            # Group by status code
            interesting_statuses = [200, 204, 301, 302, 307, 401, 403, 405, 500]
            other_statuses = [
                s for s in status_counts.keys() if s not in interesting_statuses
            ]

            for status_group, title, emoji in [
                ([200, 204], "Accessible Content", "âœ…"),
                ([301, 302, 307], "Redirects", "â†—ï¸"),
                ([401, 403], "Authentication/Authorization", "ðŸ”"),
                ([405], "Method Not Allowed", "âŒ"),
                ([500], "Server Errors", "ðŸ’¥"),
                (other_statuses, "Other Responses", "â“"),
            ]:
                group_findings = [
                    f for f in findings if f.get("status") in status_group
                ]

                if group_findings:
                    response += f"### {emoji} {title} ({len(group_findings)} items)\n\n"

                    # Sort by URL for better readability
                    group_findings.sort(key=lambda x: x.get("url", ""))

                    for i, finding in enumerate(
                        group_findings[:20], 1
                    ):  # Limit to 20 per group
                        url = finding.get("url", "Unknown")
                        status = finding.get("status", 0)
                        length = finding.get("length", 0)
                        words = finding.get("words", 0)

                        response += f"**{i}.** `{url}`\n"
                        response += f"   - **Status:** {status}\n"
                        response += f"   - **Size:** {length} bytes\n"
                        response += f"   - **Words:** {words}\n"

                        # Add context for specific status codes
                        if status == 200:
                            response += f"   - ðŸ“„ **Accessible content** - Review for sensitive information\n"
                        elif status in [301, 302, 307]:
                            response += f"   - ðŸ”„ **Redirect** - Follow to discover additional endpoints\n"
                        elif status == 401:
                            response += f"   - ðŸ”’ **Authentication required** - Potential login endpoint\n"
                        elif status == 403:
                            response += f"   - ðŸš« **Access forbidden** - Resource exists but is protected\n"
                        elif status == 405:
                            response += f"   - âš ï¸ **Method not allowed** - Try different HTTP methods\n"
                        elif status >= 500:
                            response += f"   - âš ï¸ **Server error** - Potential vulnerability or misconfiguration\n"

                        response += "\n"

                    if len(group_findings) > 20:
                        response += f"   ... and {len(group_findings) - 20} more {title.lower()}\n\n"

        else:
            response += "## âŒ No Results Found\n\n"
            response += (
                "FFUF did not discover any paths matching the specified criteria.\n"
            )
            response += "Consider:\n"
            response += "- Using different wordlists\n"
            response += "- Adjusting status code filters\n"
            response += "- Trying different file extensions\n"
            response += "- Modifying the target URL pattern\n\n"

        # Show errors/warnings if any
        if stderr:
            response += "## âš ï¸ Warnings/Errors\n\n"
            response += f"```\n{stderr[:1000]}\n```\n\n"
            if len(stderr) > 1000:
                response += "... (truncated)\n\n"

        # Security recommendations
        response += "## ðŸ›¡ï¸ Security Analysis & Recommendations\n\n"

        if findings:
            # Analyze findings for security implications
            accessible_content = [f for f in findings if f.get("status") == 200]
            auth_endpoints = [f for f in findings if f.get("status") in [401, 403]]
            redirects = [f for f in findings if f.get("status") in [301, 302, 307]]
            errors = [f for f in findings if f.get("status") >= 500]

            if accessible_content:
                response += (
                    f"### ðŸ” **{len(accessible_content)} Accessible Resources**\n"
                )
                response += "- Review all accessible content for sensitive information disclosure\n"
                response += (
                    "- Check for backup files, configuration files, or admin panels\n"
                )
                response += "- Verify proper access controls are in place\n\n"

            if auth_endpoints:
                response += f"### ðŸ” **{len(auth_endpoints)} Protected Resources**\n"
                response += "- Test authentication mechanisms for weaknesses\n"
                response += "- Check for authentication bypass vulnerabilities\n"
                response += "- Verify proper authorization controls\n\n"

            if redirects:
                response += f"### â†—ï¸ **{len(redirects)} Redirects**\n"
                response += "- Follow redirects to discover additional endpoints\n"
                response += "- Test for open redirect vulnerabilities\n"
                response += "- Verify redirect targets are intended\n\n"

            if errors:
                response += f"### âš ï¸ **{len(errors)} Server Errors**\n"
                response += (
                    "- Investigate server errors for potential vulnerabilities\n"
                )
                response += "- Check for information disclosure in error messages\n"
                response += "- Test for input validation issues\n\n"

            response += "### ðŸ“‹ **General Recommendations**\n"
            response += "1. **Manual Review** - Manually browse discovered endpoints\n"
            response += "2. **Additional Fuzzing** - Try parameter fuzzing and subdirectory discovery\n"
            response += (
                "3. **Content Analysis** - Review response content for sensitive data\n"
            )
            response += "4. **Access Controls** - Verify proper authentication and authorization\n"
            response += (
                "5. **Regular Monitoring** - Implement continuous discovery scanning\n"
            )

        else:
            response += (
                "1. **Wordlist Selection** - Try different or larger wordlists\n"
            )
            response += (
                "2. **Target Variation** - Test different URL patterns and parameters\n"
            )
            response += (
                "3. **Method Testing** - Try different HTTP methods (POST, PUT, etc.)\n"
            )
            response += "4. **Manual Exploration** - Supplement with manual directory browsing\n"
            response += (
                "5. **Alternative Tools** - Consider using different discovery tools\n"
            )

        return response

    def _parse_ffuf_output(self, output: str) -> list:
        """Parse FFUF JSON output"""
        findings = []

        if not output or not output.strip():
            return findings

        try:
            # FFUF outputs JSON in a specific format
            data = json.loads(output)

            # Extract results from the JSON structure
            if isinstance(data, dict):
                results = data.get("results", [])
                if isinstance(results, list):
                    findings.extend(results)
                elif data.get("url"):  # Single result
                    findings.append(data)
            elif isinstance(data, list):
                findings.extend(data)

        except json.JSONDecodeError:
            # Fallback: try to parse line by line if it's not a single JSON object
            for line in output.strip().split("\n"):
                line = line.strip()
                if line and line.startswith("{"):
                    try:
                        result = json.loads(line)
                        findings.append(result)
                    except json.JSONDecodeError:
                        continue

        return findings

    def is_available(self) -> bool:
        """Check if FFUF is available"""
        try:
            import subprocess

            result = subprocess.run(
                [self.tool_path, "-V"], capture_output=True, timeout=10
            )
            return result.returncode == 0
        except Exception:
            return False
